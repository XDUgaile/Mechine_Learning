# Mechine_Learning
XDU 网信院 机器学习大作业（这个大作业19、20、21级都不一样,但是大差不差，仅供参考）（18级的和21级一样|嘿嘿|）

要求如下：
基于神经网络的MNIST手写数字识别
一、实验目的
·掌握运用神经网络模型解决有监督学习问题
·掌握机器学习中常用的模型训练测试方法
·了解不同训练方法的选择对测试结果的影响
二、实验内容
MNIST数据集
本实验采用的数据集MNIST是一个手写数字图片数据集，共包含图像和对应的标签。数据集中所有图片都是28x28像素大小，且所有的图像都经过了适当的处理使得数字位于图片的中心位置。MNIST数据集使用二进制方式存储。图片数据中每个图片为一个长度为784（28x28x1，即长宽28像素的单通道灰度图）的一维向量，而标签数据中每个标签均为长度为10的一维向量。
分层采样方法
分层采样（或分层抽样，也叫类型抽样）方法，是将总体样本分成多个类别，再分别在每个类别中进行采样的方法。通过划分类别，采样出的样本的类型分布和总体样本相似，并且更具有代表性。在本实验中，MNIST数据集为手写数字集，有0~9共10种数字，进行分层采样时先将数据集按数字分为10类，再按同样的方式分别进行采样。
神经网络模型评估方法
	通常，我们可以通过实验测试来对神经网络模型的误差进行评估。为此，需要使用一个测试集来测试模型对新样本的判别能力，然后以此测试集上的测试误差作为误差的近似值。两种常见的划分训练集和测试集的方法：
	留出法（hold-out）直接将数据集按比例划分为两个互斥的集合。划分时为尽可能保持数据分布的一致性，可以采用分层采样（stratified sampling）的方式，使得训练集和测试集中的类别比例尽可能相似。需要注意的是，测试集在整个数据集上的分布如果不够均匀还可能引入额外的偏差，所以单次使用留出法得到的估计结果往往不够稳定可靠。在使用留出法时，一般要采用若干次随机划分、重复进行实验评估后取平均值作为留出法的评估结果。
	k折交叉验证法（k-fold cross validation）先将数据集划分为k个大小相似的互斥子集，每个子集都尽可能保持数据分布的一致性，即也采用分层采样（stratified sampling）的方法。然后，每次用k-1个子集的并集作为训练集，余下的那个子集作为测试集，这样就可以获得k组训练集和测试集，从而可以进行k次训练和测试。最终返回的是这k个测试结果的均值。显然，k折交叉验证法的评估结果的稳定性和保真性在很大程度上取决于k的取值。k最常用的取值是10，此外常用的取值还有5、20等。
三、实验方法设计
	介绍实验中程序的总体设计方案、关键步骤的编程方法及思路，主要包括:
1）模型构建的程序设计（伪代码或源代码截图）及说明解释 （10分）

2）模型迭代训练的程序设计（伪代码或源代码截图）及说明解释 （10分）

3）模型训练过程中周期性测试的程序设计（伪代码或源代码截图）及说明解释（周期性测试指的是每训练n个step就对模型进行一次测试，得到准确率和loss值）（10分）

4）分层采样的程序设计（伪代码或源代码截图）及说明解释 （10分）

5）k折交叉验证法的程序设计（伪代码或源代码截图）及说明解释 （10分）
四、实验结果展示
展示程序界面设计、运行结果及相关分析等，主要包括：
1）模型在验证集下的准确率（输出结果并截图）（10分）

2）不同模型参数（隐藏层数、隐藏层节点数）对准确率的影响和分析 （10分）

3）不同训练参数（batch size、epoch num、学习率）对准确率的影响和分析 （10分）

4）留出法不同比例对结果的影响和分析 （10分）

5）k折交叉验证法不同k值对结果的影响和分析 （10分）
五、实验总结及心得
